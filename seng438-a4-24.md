**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group \#:      |  24  |
| -------------- | --- |
| Student Names: |  Ahad Ali   |
|                |  Mushtaba Al Yasseen   |
|                |  Parbir Lehal   |
|                |  Athul Rajagopal   |

# Introduction

The objective of this lab is to explore mutation testing and web user interface (UI) testing in a controlled environment. To perform mutation testing, we used PITest, which automates the process and generates several mutations, which are in turn reported as either surviving or killed. After analyzing the results, we created additional test cases to kill mutants which were previously surviving, thereby improving the mutation score. Web UI testing was carried out using Selenium IDE, which is a browser extension that can record and replay actions on a webpage. Selenium was used to test and confirm that the webpage functionalities were working as intended.

# Analysis of 10 Mutants of the Range class 

#### 1. **`contains(double value)`**
    Mutation: 48. contains : Incremented (++a) double field lower → KILLED
**Analysis:** This mutation replaced the line `return (value >= this.lower && value <= this.upper);` with `return (value >= (++this.lower) && value <= this.upper);` This mutation was killed in our original test suite as it was covered by test suite `testGetContainsPositiveNumberExistsLowerBound` where the test case checked if the lower bound, `20` is in the range of 20-24. This mutation was killed as incrementing the (++a) double field lower should fail in this case which it does with the test case mentioned above as it would change the range from 20-24 to 21-24 so 20 would not be part of the range due to the mutation. 
#### 2. **`contains(double value)`**
    Mutation: 53. contains : Decremented (--a) double fieldupper → KILLED
**Analysis:** This mutation replaced the line `return (value >= this.lower && value <= this.upper);` with `return (value >= this.lower && value <= (--this.upper));` This mutation was killed in our original test suite as it was covered by test suite `testGetContainsPositiveNumberExistsUpperBound` where the test case checked if the lower bound, `42` is in the range of 42-224. This mutation was killed as decrementing the (--a) double field upper should fail in this case which it does with the test case mentioned above as it would change range from 42-224 to 42-223 so 224 would not be part of the range due to the mutation.
#### 3. **`getLength()`**
    Mutation: 6. getLength : replaced double return with 0.0d for org/jfree/data/Range::getLength → KILLED
**Analysis:** This mutation replaced the line `return this.upper - this.lower;` with `return 0.0d;` This mutation was killed in our original test suite as it was covered by test suite `testGetLengthBothBoundsPositive` where the test case found the range between 0 and 24, which is 24. This mutation was killed as the above-mentioned test case expects a length that is not 0, therefore, the mutation is killed or the test case fails as expected.
#### 4. **`getLength()`**
    Mutation: Line 123, 14. getLength: Replaced double subtraction with division → KILLED
**Analysis:** This mutation replaced the line `this.upper - this.lower` with `this.upper / this.lower`. This mutation was killed in our original test suite in the test case `testGetLengthZero` where it checked if the range of 24,24 did in fact return a length of 0. This mutation was killed by this test case, as by replacing the double subtraction with a division, the length would instead give a value of 24/24 = 1, which is not the expected value of 0, thus, failing the test case successfully.
#### 5. **`constrain(double value)`**
    Mutation: Line 188, 1. constrain: Incremented (a++) double local variable number 1 → SURVIVED
**Analysis:** This mutation post increments the parameter `value`, which is passed into the constrain method. This mutation survived because in the test case `outOfRangeConstrain`, if the value is an intenger, then the result will be the upper bound of range. For example, given a range of (0, 4), when input is incremented from 5 to 6, the result will still be the upper bound value in range, and thus this mutation still survives in our original test suite. For these cases, this can be considered an equivalent mutation. However, for cases where constrain is called on a decimal value inside a small range (e.g. `constrain(0.5)` inside a range (0, 1)), the returned value should become 1, rather than 0.5.
#### 6. **`getUpperBound()`**
    Mutation: 6. Incremented (++a) double field upper → KILLED
**Analysis:** This mutation replaced the line `return this.upper;` with `return (++this.upper);` This mutation was killed in our original test suite as it was covered by the test suite `upperBoundEqualRange()` where the test case found the upper bound in the range of 1-1. This mutation was killed as incrementing the (++a) double field upper should fail in this case which it does with the test case mentioned above. It would change the range from 1-1 to 1-2 so the upper bound changed meaning the test case caught the mutation and killed it.
#### 7. **`getUpperBound()`**
    Mutation: 1. Incremented (a++) double field upper → SURVIVED
**Analysis:** This mutation replaced the line `return this.upper;` with `return (this.upper++);` This mutation survived in our original test suite as it cannot be covered by the test suite `upperBoundEqualRange()` where the test case found the upper bound in the range 1-1. This mutation survived by incrementing the (a++) double field upper passes in this case which it does with the test case mentioned above. It won’t change the range when returning it but will change it after, thus the mutation persists and the test case is not able to catch it.
#### 8. **`constrain(double value)`**
    Mutation: 1. Negated double local variable number 1 → KILLED
**Analysis:** This mutation replaced the `value` variable with `-value`. This mutation was killed because in our original test suite it was covered by the test suite `outOfRangeConstrain`, where the test case found the constrain value in the range 1-1. This mutation was killed as negating the value variable should fail in this case which it does with the test case as mentioned above. It changed the value variable from ‘5’ to ‘-5’ and therefore the constrain returns the lower bound instead of the upper bound and the test case catches this, thus killing the mutation. 
#### 9. **`intersects()`**
    Mutation: Line 157, 9. Greater than to greater or equal → SURVIVED
**Analysis:** This mutation changes the greater-than operator (`>`) to a greater-than-or-equal-to operator (`>=`) in the condition `b1 > this.lower`. This mutation may have survived because changing the operator from `>` to `>=` can potentially increase the number of test cases that pass. If there are test cases that pass with the original code and also pass with the mutated code, then the mutation may be considered equivalent. This is because the >= operator includes the case where b1 is equal to this.lower, which was previously excluded by the > operator.
#### 10. **`intersects()`**
    Mutation: Line 157, 12. Incremented (a++) double local variable number 1 → SURVIVED
**Analysis:** This mutation increments the value of `double b0` prior to checking whether it is less than or equal to the value of `this.lower`. The mutant survived the test cases because changing the value of b0 does not affect the overall behaviour of the method. If the condition fails, the method simply continues to the else-block, where another condition is evaluated. As a result, this can be considered an equivalent mutation, and thus no test cases would be able to catch this mutation.

# Report all the statistics and the mutation score for each test class

## `Range.java`
### Original Mutation Score
![image](https://user-images.githubusercontent.com/28770261/226054770-116f6a11-5ad6-4043-8fce-5cd109dc2ed1.png)
### Updated Mutation Score
![image](https://user-images.githubusercontent.com/28770261/226055290-ad39e1c8-5eb8-4139-a633-a4027263f6ea.png)
### Additional Test Cases Generated
#### `decimalConstrain()`
This test creates a range between 0.0 and 1.0, and then calls `constrain(double value)` with `value` being 0.5. The expected output of this test is 0.5, since it is within the range. This test targets mutants that increment or decrement the value of `value`. For example, a mutant that increments 0.5 will result in `value` being 1.5. Since this is outside the range, the result will default to the upper bound 1, which is not the expected output. Prior to creating this test case, mutants survived because previous test cases did not account for a scenario in which `value` is a decimal value within a range where the difference between the upper and lower bound is no greater than 1.
#### `lowerBoundConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being 0.0. The expected output of this test is 0.0, since it is within the range and is actually the lower bound of the range. This test case was able to kill mutants because the lower bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `upperBoundConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being 5.0. The expected output of this test is 5.0, since it is within the range and is actually the upper bound of the range. This test case was able to kill mutants because the upper bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `negativeLowerOutOfBoundsConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being -2.0. The expected output of this test is 0.0, since `value` is less than the lower bound and thus defaults to the value of the lower bound.This test case was able to kill mutants because the below lower bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `positiveUpperOutOfBoundsConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being 6.0. The expected output of this test is 5.0, since `value` is greater than the upper bound and thus defaults to the value of the upper bound. This test case was able to kill mutants because the above upper bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `infiniteUpperBoundsRangeConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being positive infinity. The expected output of this test is 5.0, since `value` is greater than the upper bound and thus defaults to the value of the upper bound. This test case was able to kill mutants because the well above upper bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `negativeInfiniteUpperBoundsRangeConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being negative infinity. The expected output of this test is 0.0, since `value` is less than the lower bound and thus defaults to the value of the lower bound. This test case was able to kill mutants because the well below lower bound of the Range was not being checked beforehand, which also increased the mutation score.
#### `NaNConstrain()`
This test creates a range between 0.0 and 5.0, and then calls `constrain(double value)` with `value` being not a number(NaN). The expected output of this test is NaN, since the argument that was passed in is not a number. This test case was able to kill mutants because the NaN value compared to the bounds of the Range was not being checked beforehand, which also increased the mutation score.
#### `testGetContainsNumberNotExistsLower()`
This test was created to check the below lower bound condition of the `contains(double value)` method in the Range class. With a value of 19 and a range of 20 to 24, the expected output is obviously false. Some mutants were also called by this test case as the below lower bound of the Range was not covered by the previous tests, therefore increasing the mutation score.
#### `testCombineRangeBothNull()`
This test was created to check the both ranges as null for the `combines(Range r1, Range r2)` method in the Range class. With two null ranges, the expected output is a null combine output. Some mutants were also called by this test case as the both ranges as null of the Range was not covered by the previous tests, therefore increasing the mutation score.
#### `testCombineUpperBoundNull()`
This test was created to check the only the second range as null for the `combines(Range r1, Range r2)` method in the Range class. With second null range, the expected output is the r1 range. Some mutants were also called by this test case as the only the second range as null of the Range was not covered by the previous tests, therefore increasing the mutation score.
#### `testCombineLowerBoundNull()`
This test was created to check the only the first range as null for the `combines(Range r1, Range r2)` method in the Range class. With first null range, the expected output is the r2 range. Some mutants were also called by this test case as the only the second range as null of the Range was not covered by the previous tests, therefore increasing the mutation score.
#### `testCombineRangeValid()`
This test was created to check the both ranges as valid for the `combines(Range r1, Range r2)` method in the Range class. With two valid ranges, the expected output is the r1.lowerBound to r2.upperBound range. Some mutants were also called by this test case as the both ranges were positive and valid as part of the Range which was not covered by the previous tests, therefore increasing the mutation score.
#### `testGetLowerBoundNaN()`
This test was created to check the second range lower bound NaN value effect for the `combines(Range r1, Range r2)` method in the Range class. With the NaN lower bound, the expected output is the for the lower bound to be NaN. Some mutants were also called by this test case as the lowerBound is NaN regardless of the other lowerBound of the Range which was not covered by the previous tests, therefore increasing the mutation score.
#### `testGetLowerBoundEpsilon()`
This test was created to check the second range upper bound NaN value effect for the `combines(Range r1, Range r2)` method in the Range class. With the NaN upper bound, the expected output is the for the lower bound to be the lower bound of the smaller lowerBound range. Some mutants were also called by this test case as the lowerBound is lower bound of first range despite the NaN of upperBound of the Range which was not covered by the previous tests, therefore increasing the mutation score.
#### `testGetUpperBoundNaN()`
This test was created to check the second range upper bound NaN value effect for the `combines(Range r1, Range r2)` method in the Range class. With the NaN upper bound, the expected output is the for the upper bound to be NaN. Some mutants were also called by this test case as the upperBound is NaN regardless of the lowerBounds or upperBound of the other range of the Range which was not covered by the previous tests, therefore increasing the mutation score.
#### `doubleNaNRangeTrue()`
This test case was created to test the method isNaNRange() found in the Range class. We create a Range object both of type Double NaN and use assertTrue to check if the range isNaNRange, returning true. This method was not previously tested which is why it was able to kill many mutants and increase the mutation score.
#### `doubleNaNRangeFalse()`
This test case was created to test the method isNaNRange() found in the Range class. We create a Range object both of which are regular double numbers. Then we check if a NaN range does exist by calling the Range method isNaNRange() and assertFalse as it is not a NaN Range. This method was not previously tested which is why it was able to kill many mutants and increase the mutation score.
#### `doubleUpperBoundAndNaNLowerBoundRangeFalse()`
This test case was created to test the method isNaNRange() found in the Range class. We create a Range object, the lower bound being a NaN value and the upper bound being a number of type double. Then we check if a NaN range does exist by calling the Range method isNaNRange() and we assertFalse as there is a number as the upperbound, disqualifying the object as a NaN Range. This method was not previously tested which is why it was able to kill many mutants and increase the mutation score.
#### `doubleLowerBoundAndNaNUpperBoundRangeFalse()`
This test case was created to test the method isNaNRange() found in the Range class. We create a Range object, the upper bound being a NaN value and the lower bound being a number of type double. Then we check if a NaN range does exist by calling the Range method isNaNRange() and we assertFalse as there is a number as the lower bound, disqualifying the object as a NaN Range. This method was not previously tested which is why it was able to kill many mutants and increase the mutation score.
## `DataUtilities.java`
### Original Mutation Score
![image](https://user-images.githubusercontent.com/28770261/226055128-e6e1870f-2c82-4ceb-b541-a860aa06be78.png)
### Updated Mutation Score
![image](https://user-images.githubusercontent.com/28770261/226054934-d01acad6-6413-4421-97d5-2005faaf9ffc.png)
### Additional Test Cases Generated

#### `testCalculateRowTotalNullValues()`
This test case was updated to test the method calculateRowTotal() found in the DataUtilities class. In the original test suite, this test case tested this method by inserting null values only on the very first row, which was row "0" since the method is zero-indexed. However, by testing the method this way, the mutant of negating the Values2D data variable survived, this is because the negatiion of 0 is still 0. However, by updating the test case to instead insert null values on the second row, which was row "1", this mutant was now able to be killed, as the negation of 1 is now -1, which changes the column count integer variable, successfully killing the mutant, failing the test case as intended.

#### `testCloneEmptyData() to testCloneUBValues()`
Since we basically "over-tested" our original test suite for the DataUtilities class, we already had strong mutation coverage for the methods that we tested, and the mutations that survived the original test suite consisted of unreachable code, or were unable to be killed, like many of the post increment/decrement mutatants where they were returned or used before the increment/decrement had an effect at all. Thus, other than the updated test case above, the really only way to increase the mutation coverage for the DataUtilities class was to cover methods that were previously uncovered, such as the clone method. Using boundary and equivalent class testing, we were basically able to cover and kill almost all the mutants for the clone method except the ones that were essentially "unkillable" like the mutant which changes less than to not equal to, which had no effect on the loop in this case. Likewise, from empty to null to maximum positive value data values, we were able to kill all but two "unkillable" mutants for the clone method, increasing our mutation coverage significantly for the DataUtilities class.

# Analysis drawn on the effectiveness of each of the test classes

With the additional test cases added to the Range and DataUtilities test classes, we were able to meet the requirement of increasing the mutation coverage by at least 10% in each file. For Range, the mutation coverage went from 12% to 24%, thereby increasing by 12% or essentially doubling. This exceeds the 10% requirement and also ensures that our code coverage is more robust as it handles all the boundary values and frequent mistakes that are found in source codes like a `<=` instead of a `<` for example. Likewise, in DataUtilites, the mutation coverage went from 68% to 82%. This means the mutation coverage increase was even higher for this file compared to the Range file, with an increase of 14%. This also exceeds the 10% requirement and suggests our test suite after working on it in the past three labs is strong and robust enough to detect software faults. 

# A discussion on the effect of equivalent mutants on mutation score accuracy

As taught in class, a mutant enhances the test suite by helping catch typical faults or seeding bugs to find bugs. Killed mutants means changing the source code changes the test results which is good as our test cases are effecting in catching faults. Meanwhile, surviving is bad and the opposite. One type of mutatnt is equivalent mutant which is that it always acts in the same behaviour as the original program. The provided example from class is `x= a + b` and `x = a - (-b)`. However, this is not interesting from a mutation testing perspective as it can not be killed. As such, the mutation score accuracy is understated or pessimisticly inaccurate as compared to the actual mutation score accuracy.

# A discussion of what could have been done to improve the mutation score of the test suites

Mutation scores are dependent on the assassination of mutants by test cases. Generally speaking, our pre existing test cases covered many of the mutants. It became difficult and sometimes impossible to achieve 100% mutation coverage because of uncontrollable conditions. For example, when trying to kill the mutant (a++) for the method of getUpperBound(). We realized this mutant is impossible to kill because it is incrementing after the value is returned, therefore, our test cases have no reach to alter/kill this mutant. Range.java lacked overall mutant coverage prior to starting the lab. This is because of the large number of methods pertaining to this class. Many of the coverage increase we were able to achieve was through creating test cases for methods that were not previously tested. Whereas, DataUtilities.java had a higher pre existing mutation score, due to having test cases that covered all methods, making it harder to increase. Overall, our team used PIT statement checks to increase our mutation score, and understand that 100% coverage isn’t attainable. 

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing involves making small changes to an existing code base called mutations to determine whether the tests used to check the code can detect these changes. The purpose of mutation testing is to improve the quality of software written by uncovering weaknesses in the test suite. These mutations help to detect the faults in the code by evaluating the overall test suite and its effectiveness. If a mutation survives the test suite, it is a clear identifier of the weakness of the test sutie and how it can be improved. The key advantages of mutaion testing are that it can help identify weaknesses in the test suite as previously mentioned. consequently mutation testing can improve the quality of code, through fault detection. Another advantage is that it increases the test coverage. This is done by identifying the areas of code that have not been properly tested yet. Mutation testing also helps find unorthodox bugs, which may be hidden through other testing methods. This can be put into practice because mutation testing introduces subtle changes into the code that reveal the weaknesses of the test suite. Mutation testing ultimately can save time and resources by finding the faults earlier on in the development cycle. With that being said, there are a few disadvantages that mutation testing poses. One of those can be the high level of expertise required in analyzing and understanding mutations. Sometimes it can be hard to interpret what the PIT mutation is referring to and how the test sutie isn't able to adequately kill the mutation. Secondly, mutation testing doesn't always translate over to reporting faults into the code, even when a mutation survives. Thirdly, mutation testing is limited in scope, it has the chance of missing many faults in the code, depended upon how the code handles certain edge cases. Lastly, mutation testing can be expensive in terms of using in very large code bases, requires running many tests simutaneously and is rigiorous computationally. 

# Explain your SELENIUM test case design process

First and foremost, we explored the webpage and made note of what functionalities it offered. This provided us with an understanding of which core UI components we felt needed to be tested. The functionalities we ultimately decided to test were:
-  Login
-  Register
-  Add to Cart
-  Remove from Cart
-  Sign Out
-  Add to List
-  Search
-  Filter

Then, we considered the step-by-step process by which each functionality could be used. For example, in the case of Search, it required clicking on the search bar, typing in the query, and clicking on the search button. Once we determined the intended process, we considered cases of additional or erroneous user input. Using the same example of Search, this included a test case in which the search query was a random sequence of characters, which represents an invalid input. Finally, all the constructed cases were recorded using Selenium IDE and then appended with assert statements to ensure that the ouput was as intended. 

# Explain the use of assertions and checkpoints

Assertions and checkpoints are utilised to ensure that the UI functionality is working as intended and has not been diverted during its execution. They both do so by checking the current value of a target against its expected value defined by the tester. The difference lies in the action that each takes if the result of the comparison is a mismatch. An assertion will stop the execution entirely and display an error message. Conversely, a checkpoint will allow the execution to continue, although it will also display an error message. Ultimately, where and how the two are used is up to the tester. However, in the majority of cases, checkpoints should be used throughout the program flow, while asserts should typically be saved for the final check or critical points in the execution flow. In our case, we did not think adding checkpoints were necessary, as our tests were short and simple enough that a single assert statement would be adequate to verify the results.

# How did you test each functionality with different test data

We were able to test functionalities like Filter and Add to Cart with different test data by using variables. Using the `store text` function in Selenium IDE, we assigned the value of a target to a variable, which would then be compared in an assert statement. For instance, when testing the Add to Cart functionality, we stored the name of the item being added as a variable. Then, when viewing the cart, we checked to see whether the name of the item in the cart matches the variable. This way, we are able to test adding any items to the cart, without having to manually change the expected values.  
  
For some functionalities, like Search, it was not possible to automate the validation using a variable. This is because there was no way to expect what the output of the search would be until after it was completed. In these cases, we had little choice but to manually update the expected values each time the input data changed.

# Discuss advantages and disadvantages of Selenium vs. Sikulix
Selenium is relatively straightforward to understand and use in a web development context, since it identifies elements using HTML and CSS selectors. In this way, it is likely more intuitive than Sikulix. With tools like Selenium IDE, it is also possible to create and run tests with very little programming involved, saving valuable time for developers. However, Selenium does have constraints in terms of its versatility. For instance, it cannot easily detect attributes like placeholder text in an input field. Moreover, for some functions, components have to be identified via their id attribute, which is not always possible depending on how the page was developed. Sikulix has the advantage in this capacity, since it primarily uses image recognition to detect UI components. This means it can potentially capture a much wider variety of targets than Selenium. However, this comes at the expense of accuracy, as the image recognition system may not always correctly identify a target, unlike how a CSS selector would. 

# How the team work/effort was divided and managed

Our team intially spent time meeting to work on setting up PIT and running the mutation test on our original test suite. Once we had an adequate understanding of how mutation testing worked using PiTest, we evely set individual goals to increase mutation coverage. Each person was told to increase mutation coverage by at least 5%, and divided up the relative class based on our previous pairs. For example, Parbir and Mushtaba were a pair, therefore one of them worked on increasing mutation coverage for DataUtilities, and the other did the same respectively for Range. If we needed assistance we would reach out to our pair to keep things consistent and efficient. However, if a pair ran into a bigger, urgent issue, then we'd setup a group meeting to address it. Overall, this divide allowed us to increase mutation coverage by 10% for Range test and almost 15% for DataUtilities. 

After finishing the first part, our pairs scattered into more individual work for the GUI testing. We investigated Costco, split up functionalities in order to avoid overlap and worked on our respective Selenium tests. At the end we made sure to demonstrate our tests prior to the lab to ensure everyone was on the same page and nobody was unclear of the standard of work required. 

# Difficulties encountered, challenges overcome, and lessons learned

The difficulties encountered in this lab mainly revolved around running/reading the PIT mutation tests. Since we found the instructions to be quite confusing, we ran into difficulties at first trying to get the PIT mutation tests to run. However, we realized that the PIT mutation tests take quite some time to finish running/execute all mutants, which we thought was an infinite loop at first causing confusion, and a great amount of wasted time. Futhermore, the length it took to run the PIT mutation tests every time as also another challenge that we had to overcome, as it amounted to a large amount of time wasted, so in order to reduce this, we tried to run the PIT mutation tests as infrequently as possible. Likewise, we also had some difficulties trying to read/understand the PIT mutation summaries at first, especially when it came to the specific syntax that PIT uses when identifying specific variables for mutants. In order to understand this syntax, we had to do some external research to understand how to read the PIT mutation summaries properly, which then allowed us to learn and understand what specific variable PIT was referrring to, and create test cases to kill these mutants.

# Comments/feedback on the lab itself

This lab was very long, and could have been split up into two different labs, as concepts did not overlap. It would have been helpful to have a more in depth setup guide, maybe even a video walk through to ensure that each group was able to get through the rather less significant, but crutial portion of the lab. It would've also been helpful to have had a note discussing the impossiblity of killing some mutants through test cases. For Selenium, we felt the instructions were somewhat vague. It could have talked a bit more about the significances of having assert commands and how that could be most effectively achieved. Overall, we enjoyed learning about mutation testing, understanding the advantages and disadvantages first hand. Additionally, the Selenium testing was also very intuitive and gave insight on how to perform more automated test cases for GUI, in comparison to the more manual JUnit tests we have done in the past. Having used both tools gave us the ability to directly compare the two and see the differences, which can be seen as beneficial. 
